Road map:
--> Random walk in latent space with GAN
    Style transfer
    Texture transfer
    ?

Current sprint:
--> Baseline GAN from tutorial (https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)
    Random walk in latent space
    Higher resolution images

Current task:
--> Get training to run
    Save generator output on fixed noise
    Use metrics/plotting from meta
    Save results
    Tests
    Refactoring

----------------------------------------------------------------------------------------

Future plans:

Refactoring:
- Make number of generator/discriminator layers options
- Initialization options

----------------------------------------------------------------------------------------

Reading:

- Read through GAN papers
  - Generative Adversarial Networks (Goodfellow)
  - Unsupervised Representation Learning with Deep Convolutional Generative Adversarial
    Networks (Radford)
  - BigGAN?
  - BigBiGAN?
  - Look for more recent GAN stuff
  - Look into GAN literature about this point: Why, when training the generator, do we
    only compute the loss using fake images? Would it not be better to train the
    generator so that the discriminator classifies fake images as real as well as real
    images as fake?
- Read through VAE literature (especially the recent NVAE)
- Read distill.pub articles about image generation

----------------------------------------------------------------------------------------

Misc info:

Flowers dataset came from: https://www.kaggle.com/alxmamaev/flowers-recognition
